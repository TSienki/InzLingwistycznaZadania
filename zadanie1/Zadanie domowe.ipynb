{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inżynieria lingwistyczna\n",
    "Ten notebook jest oceniany półautomatycznie. Nie twórz ani nie usuwaj komórek - struktura notebooka musi zostać zachowana. Odpowiedź wypełnij tam gdzie jest na to wskazane miejsce - odpowiedzi w innych miejscach nie będą sprawdzane (nie są widoczne dla sprawdzającego w systemie).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1 - tokenizacja (12 pkt)\n",
    "\n",
    "Jedną z nowoczesnych technik tokenizacji jest BPE - byte-pair encoding [1]. Technika ta polega na podzielenie słów na częste podsłowa (morfemy). W przeciwieństwie do podejść lingwistycznych, wymagających reguł tworzenia morfemów, BPE wyznacza je automatycznie poprzez wyznaczenie najczęstszych przylegających do siebie sekwencji znaków które występują obok siebie.\n",
    "\n",
    "Algorytm przebiega w następujących krokach.\n",
    "1. Podziel wszystkie słowa na symbole (początkowo pojedyncze znaki)\n",
    "2. Wyznacz najczęściej występującą obok siebie parę symboli \n",
    "3. Stwórz nowy symbol będący konkatenacją dwóch najczęstszych symboli.\n",
    "\n",
    "Uwaga 1: każde słowo zakończone jest specjalnym symbolem końca wyrazu.\n",
    "\n",
    "Uwaga 2: tworzenie nowego symbolu nie powoduje usuniecie starego tj. zawsze jednym z możliwych symboli jest pojedynczy znak, ale jeśli można to stosujemy symbol dłuższy.\n",
    "\n",
    "Przykład: korpus w którym występuje ,,ala'' 5 razy i ,,mama 10 razy''\n",
    "1. Dzielimy słowa na symbole ,,a l a END'' ,,m a m a END''  gdzie END jest symbolem końca wyrazu.\n",
    "2. Najczęstsza para obok siebie to ,,m a'' (20) razy\n",
    "3. Nowy symbol ,,ma''\n",
    "4. Nowy podział ,,a l a END'' ,,ma ma END''\n",
    "5. Najczęstsza para ,,ma ma'' (10) razy\n",
    "6. Nowy symbol ,,mama''\n",
    "7. Nowy podział ,,a l a END'' ,,mama END''\n",
    "8. itd.\n",
    "\n",
    "W pliku ,,brown_clusters.tsv'' pierwsza kolumna to identyfikator skupienia (nie używamy w tym zadaniu), druga kolumna to wyrazy, a trzecia to ich liczności w pewnym korpusie tweetów. Zaimplementuj technike BPE na tych słowach.\n",
    "\n",
    "Zaimplementuj algorytm BPE wykonujący `number_of_iterations` iteracji (łączeń symboli).\n",
    "\n",
    "[1] Sennrich, R., Haddow, B., and Birch, A. (2016). Neural machine translation of rare words with subword units. In ACL 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ff3b90528fdb50de90c5c946c157e21",
     "grade": false,
     "grade_id": "cell-93d78a28d4e25cbc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "brown_df = pd.read_csv('brown_clusters.tsv', sep='\\t', header=0, names=['cluster', 'word', 'count'])\n",
    "\n",
    "number_of_iterations = 10\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "brown_df = pd.read_csv('brown_clusters.tsv', sep='\\t', header=0, names=['cluster', 'word', 'count'])\n",
    "\n",
    "number_of_iterations = 10\n",
    "def preform_bpe(brown_df, number_of_iterations):\n",
    "    \"\"\"\n",
    "    Funckcja przyjmuje ramkę w formacie analogicznym do obiektu brown_df (wczytany wyżej)\n",
    "     oraz liczbę iteracji.\n",
    "    Wyjściem funkcji powinna być lista słów z poszczególnymi tokenami/symbolami oddzielonymi spacją.\n",
    "    Za znak końca wyrazu przyjmij END. \n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    class Counter(dict):\n",
    "         def __missing__(self, key):\n",
    "            return 0\n",
    "        \n",
    "    split_words = [list(word) + [\"END\"] for word in brown_df[\"word\"] if type(word) is not float]\n",
    "    words_count = list(brown_df[\"count\"])\n",
    "    for i in range(number_of_iterations):\n",
    "        pairs = Counter()\n",
    "        # generate pairs\n",
    "        for split_word, count in zip(split_words, words_count):\n",
    "            for pair in zip(split_word[:-1], split_word[1:]):\n",
    "                pairs[pair] += count\n",
    "        biggest_pair = max(pairs, key=pairs.get)\n",
    "#         print(i, biggest_pair)\n",
    "        joined_biggest_pair = \"\".join(biggest_pair)\n",
    "        new_split_words = []\n",
    "        \n",
    "        # generate new split words \n",
    "        for split_word in split_words:\n",
    "            new_split_word = []\n",
    "            matched_in_last_iteration = False\n",
    "            for pair in zip(split_word[:-1], split_word[1:]):\n",
    "                if pair == biggest_pair and not matched_in_last_iteration:\n",
    "                    new_split_word.append(joined_biggest_pair)\n",
    "                    matched_in_last_iteration = True\n",
    "                    continue \n",
    "                elif not matched_in_last_iteration:\n",
    "                    new_split_word.append(pair[0])\n",
    "                matched_in_last_iteration = False\n",
    "            if not matched_in_last_iteration:\n",
    "                new_split_word.append(pair[1])\n",
    "            new_split_words.append(new_split_word)\n",
    "        split_words = new_split_words\n",
    "    \n",
    "    return [\" \".join(split_word) for split_word in split_words]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test implementacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfff70f711bf389f0f1cd969e7c3a413",
     "grade": true,
     "grade_id": "cell-7e952fa8dcd136fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_list_equal\n",
    "data = {'cluster': range(2), 'word':['ala', 'mama'], 'count': [5,10]}\n",
    "df = pd.DataFrame (data, columns = ['cluster', 'word', 'count'])\n",
    "vocab = preform_bpe(df, 1)\n",
    "assert_list_equal(vocab, ['a l a END', 'ma ma END'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spraw aby Twoja implementacja wypisywała kolejne łączone ze sobą symbole i uruchom Twoją funkcję na np. 50 iteracji, obserwując jakie tokeny są tworzone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\ iEND',\n",
       " '/ i / END',\n",
       " 't o d a y - iEND',\n",
       " 'n o w iEND',\n",
       " '# y ou e v erEND',\n",
       " 'i f in a ll yEND',\n",
       " '「 iEND',\n",
       " '- i - END',\n",
       " 'in e v aEND',\n",
       " '» iEND',\n",
       " 'w ha tt a y aEND',\n",
       " 'i i i i i i i i i iEND',\n",
       " '\\ue6d1 END',\n",
       " 'i k in d aEND',\n",
       " 'l o l - iEND',\n",
       " 'i a c t u a ll yEND',\n",
       " 'w a d d y aEND',\n",
       " '# a s l on g a s y ou END',\n",
       " 'd o y ou END',\n",
       " '\\u200e \\u200b iEND',\n",
       " 'i ̇ END',\n",
       " 'ï END',\n",
       " '# l o l a t g i r l s w h oEND',\n",
       " '# r t i f y ou END',\n",
       " 'i j s tEND',\n",
       " '« iEND',\n",
       " '• iEND',\n",
       " 'w h o d aEND',\n",
       " 'w ha d y aEND',\n",
       " ') iEND',\n",
       " '+ iEND',\n",
       " '# y ou r f a c e m a k e s m eEND',\n",
       " 'i i i i i i i iEND',\n",
       " '` iEND',\n",
       " 'i i i i i i iEND',\n",
       " 'i al r ea d yEND',\n",
       " '_ iEND',\n",
       " '# y ou m a k e m eEND',\n",
       " '* iEND',\n",
       " '| iEND',\n",
       " '# u r b o y f r i en d e v erEND',\n",
       " 'w h en iEND',\n",
       " 'ι END',\n",
       " \"d on ' t c h aEND\",\n",
       " \"w h o ' d aEND\",\n",
       " 'd y ou END',\n",
       " 'w ha d d a y aEND',\n",
       " 'i on l yEND',\n",
       " 'i j u s sEND',\n",
       " 'i al w a y sEND',\n",
       " 'i i i i iEND',\n",
       " 'd on c h aEND',\n",
       " '( iEND',\n",
       " \"d ' y aEND\",\n",
       " 'ı END',\n",
       " '# u e v erEND',\n",
       " 'in e v erEND',\n",
       " 'i - iEND',\n",
       " 'i j u sEND',\n",
       " '/ / iEND',\n",
       " 'i st i ll END',\n",
       " 'w ha d d y aEND',\n",
       " \"d ' y ou END\",\n",
       " 'i r ea ll yEND',\n",
       " 'd on t c h aEND',\n",
       " 'i j u s tEND',\n",
       " 'tEND',\n",
       " '- iEND',\n",
       " 'i y ou END',\n",
       " '# in n o w a y s ha p e or f or m END',\n",
       " '( y ou END',\n",
       " '/ / w eEND',\n",
       " '/ / u END',\n",
       " '# m en m ar r y w om en th a tEND',\n",
       " '/ w eEND',\n",
       " 's e l f - e d u c a t i on END',\n",
       " '# r ea l g r an d m a sEND',\n",
       " '/ y ou END',\n",
       " '# s h ou t ou tt o g i r l s w h oEND',\n",
       " '# b o y s w h oEND',\n",
       " 'i / w eEND',\n",
       " '# s h ou t ou tt o th e g u y s th a tEND',\n",
       " '/ / y ou END',\n",
       " '# i l o v e p e o p l e th a tEND',\n",
       " '# n o t a ll b l a c k p e o p l eEND',\n",
       " '# i c an t st an d p e o p l e th a tEND',\n",
       " '# s h ou t ou tt o th e g i r l s th a tEND',\n",
       " '- th e yEND',\n",
       " '- w eEND',\n",
       " '# h o w m an y p e o p l eEND',\n",
       " '- y ou END',\n",
       " 'w eEND',\n",
       " '# a q u ar i an sEND',\n",
       " 't th e yEND',\n",
       " 'th w yEND',\n",
       " 'g u i l d en st er n END',\n",
       " \"d ' u END\",\n",
       " '# i ha t e m al e s w h oEND',\n",
       " 't e h yEND',\n",
       " 'th r yEND',\n",
       " 'i f y ou END',\n",
       " '# h ou s e h i p p o sEND',\n",
       " 'th e u END',\n",
       " 'th e e yEND',\n",
       " '# i ha t e f e m al e s w h oEND',\n",
       " 'th e y yEND',\n",
       " 'th e yEND',\n",
       " 'v i o l e t sEND',\n",
       " 'e h oEND',\n",
       " 'w h o ’ dEND',\n",
       " 'w h o t f END',\n",
       " 'w h o ’ v eEND',\n",
       " 'w h o dEND',\n",
       " '< U R L - r ea l . c om > END',\n",
       " '# i l i k e p e o p l e w h oEND',\n",
       " '- w h oEND',\n",
       " 'w h 0 END',\n",
       " 'w h u END',\n",
       " 'w h oEND',\n",
       " \"w h o ' v eEND\",\n",
       " 's s h eEND',\n",
       " 's er - u e b er w a c h erEND',\n",
       " 's h h eEND',\n",
       " 't e st a st er i s k END',\n",
       " '# m y d u m b a s sEND',\n",
       " 's j eEND',\n",
       " 't a c h om a st erEND',\n",
       " 'i al m o s tEND',\n",
       " 'i d on eEND',\n",
       " '# w ha t i f iEND',\n",
       " 'h e / s h e / i tEND',\n",
       " '$ h eEND',\n",
       " '# w ha t i f g o dEND',\n",
       " '# i h ea r d c h u c k n or r i sEND',\n",
       " '# f m h 2 0 11 END',\n",
       " '# i h ea r d b o w w o w END',\n",
       " 'b l d _ 6 0 0 _ k w h END',\n",
       " 'b l d _ 6 5 0 _ k w h END',\n",
       " 's h e e eEND',\n",
       " '# f m 2 0 11 END',\n",
       " '- s h eEND',\n",
       " '- h eEND',\n",
       " 's / h eEND',\n",
       " 's h e / h eEND',\n",
       " '- i tEND',\n",
       " 's h e eEND',\n",
       " 'h e / s h eEND',\n",
       " 'h eEND',\n",
       " 's h eEND',\n",
       " '< U R L - i . v e > END',\n",
       " \"l ' v eEND\",\n",
       " 'th e y v END',\n",
       " \"y ou \\\\ ' v eEND\",\n",
       " \"i ' b eEND\",\n",
       " '< U R L - i h ea r t m o v i e s . or g > END',\n",
       " 'i w ou l d aEND',\n",
       " 'w e ` v eEND',\n",
       " \"i ha v en ' tEND\",\n",
       " '# i ha v en e v erEND',\n",
       " \"a : i ' v eEND\",\n",
       " 'w e v END',\n",
       " 'w e ´ v eEND',\n",
       " \"y u ' v eEND\",\n",
       " 'u ’ v eEND',\n",
       " \"- i ' v eEND\",\n",
       " \"th er e ' v eEND\",\n",
       " \"i ' d aEND\",\n",
       " '< U R L - v oo m a x er . c om > END',\n",
       " \"th a t ' v eEND\",\n",
       " \"w e ' v END\",\n",
       " 'y ou ´ v eEND',\n",
       " 'i v e eEND',\n",
       " \"i ' d ' v eEND\",\n",
       " 'y ou ` v eEND',\n",
       " \"i \\\\ ' v eEND\",\n",
       " 'y ou v END',\n",
       " \"y ou ' v END\",\n",
       " '# n e v er ha v e i e v erEND',\n",
       " \"u ' v END\",\n",
       " '< U R L - n a u g h t y d o g . c om > END',\n",
       " 'i ha v en tEND',\n",
       " \"i v ' eEND\",\n",
       " 'th e y ’ v eEND',\n",
       " '# ha v e y ou e v erEND',\n",
       " 'i ´ v eEND',\n",
       " 'i ` v eEND',\n",
       " '# ha v e u e v erEND',\n",
       " 'th e y v eEND',\n",
       " \"i ' v END\",\n",
       " '0 . 0 0 % END',\n",
       " 'w e v eEND',\n",
       " 'u v eEND',\n",
       " 'w e ’ v eEND',\n",
       " \"u ' v eEND\",\n",
       " 'y ou ’ v eEND',\n",
       " 'y ou v eEND',\n",
       " 'i ’ v eEND',\n",
       " \"th e y ' v eEND\",\n",
       " \"i ' v eEND\",\n",
       " 'i v eEND',\n",
       " \"y ou ' v eEND\",\n",
       " \"w e ' v eEND\",\n",
       " 'n oo oo oo tEND',\n",
       " 'n o tt tt tt tEND',\n",
       " 'n o h tEND',\n",
       " 'y ou ha v eEND',\n",
       " '/ n o t / END',\n",
       " 'n o i tEND',\n",
       " '- n o t - END',\n",
       " 'n o tt tt t tEND',\n",
       " 'n oo oo o tEND',\n",
       " \"n ' tEND\",\n",
       " 'n n o tEND',\n",
       " 'n a h tEND',\n",
       " '_ n o t _ END',\n",
       " 'd e s er v e d l yEND',\n",
       " 'n o tt tt tEND',\n",
       " 'n oo oo tEND',\n",
       " 'n o t - END',\n",
       " 'n oo o tEND',\n",
       " 'n oo tEND',\n",
       " 'n toEND',\n",
       " 'n o tt t tEND',\n",
       " 'n o tt tEND',\n",
       " 'r i g h t f u ll yEND',\n",
       " 'n a w tEND',\n",
       " 'n 0 tEND',\n",
       " 'n o t tEND',\n",
       " 'n o tEND',\n",
       " 'n tEND',\n",
       " 'g o tt n END',\n",
       " 'b 3 3 n END',\n",
       " 'b e e e e e en END',\n",
       " 'g o tt on END',\n",
       " 's u c c e s s f u l yEND',\n",
       " 'b e e e e en END',\n",
       " 'b e en n END',\n",
       " 'u n d er g on eEND',\n",
       " 'b e e e en END',\n",
       " 'b e e en END',\n",
       " 'b e en END',\n",
       " 'g o tt en END',\n",
       " 'j u x tEND',\n",
       " '/ / j u s tEND',\n",
       " 'j u s tt tt tEND',\n",
       " 'j x tEND',\n",
       " '# s p or c l eEND',\n",
       " 'j st tEND',\n",
       " 'j u r tEND',\n",
       " 'j y sEND',\n",
       " '/ j u s tEND',\n",
       " '- j u sEND',\n",
       " 'j y s tEND',\n",
       " 'd d e u b e l END',\n",
       " 'j u s tt t tEND',\n",
       " 'j u s s s s tEND',\n",
       " 'j u $ tEND',\n",
       " 'j u u sEND',\n",
       " 'j s s tEND',\n",
       " 'j u u u u u s tEND',\n",
       " 'k u s tEND',\n",
       " 'j h u sEND',\n",
       " 'j u s s s sEND',\n",
       " 'j h u s sEND',\n",
       " 'j u st sEND',\n",
       " 'j u s s s tEND',\n",
       " 'j u s x END',\n",
       " 'j u x x END',\n",
       " 'j z tEND',\n",
       " 'j u z z END',\n",
       " 'j u d tEND',\n",
       " '< U R L - w oo . l y > END',\n",
       " 'j u h sEND',\n",
       " 'j u u u u s tEND',\n",
       " 'j j u s tEND',\n",
       " 'j u z tEND',\n",
       " 'j u s tt tEND',\n",
       " 'j u st e dEND',\n",
       " 'j u s r END',\n",
       " 'j u u u s tEND',\n",
       " 'j u t sEND',\n",
       " 'j u s yEND',\n",
       " 'j u u s tEND',\n",
       " 'j u a tEND',\n",
       " 'j u s z END',\n",
       " '# j u s tEND',\n",
       " 'j s sEND',\n",
       " 'j u s s sEND',\n",
       " '< U R L - b u y tt er . c om > END',\n",
       " 'j u s s tEND',\n",
       " 'j z END',\n",
       " '- j u s tEND',\n",
       " '# d on t a c t l i k e y ou n e v erEND',\n",
       " 'j u tEND',\n",
       " 'j u st tEND',\n",
       " 'j u x END',\n",
       " 'j s u tEND',\n",
       " 'j u z END',\n",
       " 'j s tEND',\n",
       " 'j u s sEND',\n",
       " 'j u s tEND',\n",
       " 'j u sEND',\n",
       " \"a in \\\\ ' tEND\",\n",
       " 'a in ´ tEND',\n",
       " \"a ' in tEND\",\n",
       " 'a i t n END',\n",
       " 'a in yEND',\n",
       " 'w u s z END',\n",
       " 'a y n tEND',\n",
       " 'a in n tEND',\n",
       " 'i an tEND',\n",
       " \"an ' tEND\",\n",
       " 'a in eEND',\n",
       " 'a in ` tEND',\n",
       " 'a in n END',\n",
       " 'a in t tEND',\n",
       " 'a i in tEND',\n",
       " 'i a in tEND',\n",
       " 'a in ’ tEND',\n",
       " 'an i tEND',\n",
       " 'a in END',\n",
       " 'a in tEND',\n",
       " \"a in ' tEND\",\n",
       " 's h ou d aEND',\n",
       " 's h ou l d n aEND',\n",
       " 's h ou l aEND',\n",
       " \"w ou l d n ' t ' v eEND\",\n",
       " \"s h ou l d n ' t ' v eEND\",\n",
       " 's h ou l d v END',\n",
       " \"s h u d ' v eEND\",\n",
       " 'h an tEND',\n",
       " \"ha v ' n tEND\",\n",
       " 'c l d aEND',\n",
       " 'w l d v eEND',\n",
       " \"s h ou l d ' aEND\",\n",
       " 'w ou l d a aEND',\n",
       " 's h ou l d d aEND',\n",
       " 'w u l d v eEND',\n",
       " \"w u d ' v eEND\",\n",
       " 'w ou l d d aEND',\n",
       " 's h u l d v eEND',\n",
       " 's h ou l d a aEND',\n",
       " \"ha v e ' tEND\",\n",
       " 'c ou l d ’ v eEND',\n",
       " 'ha v en t tEND',\n",
       " 's h l d v eEND',\n",
       " 'c u d v eEND',\n",
       " \"m a y ' v eEND\",\n",
       " \"h v n ' tEND\",\n",
       " 'w ou l d ’ v eEND',\n",
       " 'a v n tEND',\n",
       " 'w l d aEND',\n",
       " 's h ou l d ’ v eEND',\n",
       " 'c u l d aEND',\n",
       " 'ha v en ´ tEND',\n",
       " 's h l d aEND',\n",
       " 'm i g h t v eEND',\n",
       " 'ha v en ` tEND',\n",
       " 'ha d n ’ tEND',\n",
       " '# g l o c al u r b an END',\n",
       " 'h v en tEND',\n",
       " 's h u d v eEND',\n",
       " 'w u d v eEND',\n",
       " \"ha v e ' n tEND\",\n",
       " 'c u d d aEND',\n",
       " 'm i g h t aEND',\n",
       " 'w u l d aEND',\n",
       " 's h u l d aEND',\n",
       " 'w u d d aEND',\n",
       " 's h u d d aEND',\n",
       " 'w u d aEND',\n",
       " 's h u d aEND',\n",
       " 'm u st v eEND',\n",
       " 'h v n tEND',\n",
       " \"m i g h t ' v eEND\",\n",
       " 'ha d n tEND',\n",
       " \"ha v n ' tEND\",\n",
       " 'ha v en ’ tEND',\n",
       " 'c ou l d v eEND',\n",
       " 'm u st aEND',\n",
       " \"m u st ' v eEND\",\n",
       " 'w ou l d v eEND',\n",
       " 's h ou l d v eEND',\n",
       " 'ha v n tEND',\n",
       " 'c ou l d aEND',\n",
       " \"c ou l d ' v eEND\",\n",
       " 'w ou l d aEND',\n",
       " \"ha d n ' tEND\",\n",
       " \"s h ou l d ' v eEND\",\n",
       " \"w ou l d ' v eEND\",\n",
       " 's h ou l d aEND',\n",
       " \"ha v en ' tEND\",\n",
       " 'ha v en tEND',\n",
       " 'n e v v aEND',\n",
       " 'n e e e e v erEND',\n",
       " 'n e v e tEND',\n",
       " 'n e e e v erEND',\n",
       " 'en v erEND',\n",
       " 'n er v erEND',\n",
       " 'n e e v erEND',\n",
       " 'n e v a a aEND',\n",
       " 'b e v erEND',\n",
       " '# in e v erEND',\n",
       " 'g l a d yEND',\n",
       " 'n e v e erEND',\n",
       " '- n e v erEND',\n",
       " \"n e ' erEND\",\n",
       " 'l e t c h aEND',\n",
       " 'l e t c h u END',\n",
       " 'n e v er r r r END',\n",
       " 'n v aEND',\n",
       " 'n e v a h END',\n",
       " 'n e v a aEND',\n",
       " 'n e v er r r END',\n",
       " 'n v erEND',\n",
       " 'n e v er r END',\n",
       " '# n e v erEND',\n",
       " 'n e v r END',\n",
       " 'g l a d l yEND',\n",
       " 'n v r END',\n",
       " 'n e v erEND',\n",
       " 'n e v aEND',\n",
       " 'e v u r END',\n",
       " 'e v a a a a aEND',\n",
       " 'e v e aEND',\n",
       " 'e v e e e erEND',\n",
       " 'e v er r r r r r r r r END',\n",
       " 'e v er r r r r r r r END',\n",
       " 'e v e e erEND',\n",
       " 'e v a a a aEND',\n",
       " 'e v e erEND',\n",
       " 'n e v ar END',\n",
       " 'e v er r r r r r r END',\n",
       " 'e v a a aEND',\n",
       " 'e v a aEND',\n",
       " 'e v er r r r r r END',\n",
       " 'e v er r r r r END',\n",
       " 'e v a h END',\n",
       " 'e v er r r r END',\n",
       " 'e v er r END',\n",
       " 'e v er r r END',\n",
       " 'e v r END',\n",
       " 'e v ar END',\n",
       " 'e v aEND',\n",
       " 'e v erEND',\n",
       " 'on l eEND',\n",
       " 'in l yEND',\n",
       " 'on l e eEND',\n",
       " 'on l u END',\n",
       " 'on y l END',\n",
       " 'on ll yEND',\n",
       " 'on l tEND',\n",
       " 'on l y y yEND',\n",
       " 'o l n yEND',\n",
       " '- on l yEND',\n",
       " '0 n l yEND',\n",
       " 'on l i iEND',\n",
       " 'on yEND',\n",
       " 'on l y yEND',\n",
       " 'on l yEND',\n",
       " 'on l iEND',\n",
       " 'g e t 2 END',\n",
       " 'n e c c e s ar i l yEND',\n",
       " 'n e c c e s s ar i l yEND',\n",
       " 'e e e m END',\n",
       " 'e v er n END',\n",
       " 'n e v en END',\n",
       " 'l e t e m END',\n",
       " 'e v en n n END',\n",
       " 'e v e b END',\n",
       " 'e e en END',\n",
       " 'e v e m END',\n",
       " 'e v e en END',\n",
       " '< U R L - g t p 1 2 3 . c om > END',\n",
       " '- e v en END',\n",
       " \"10 x ' sEND\",\n",
       " \"m a k e ' e m END\",\n",
       " \"l e t ' e m END\",\n",
       " 'e v en n END',\n",
       " 'e e m END',\n",
       " 'e v n END',\n",
       " 'e v en END',\n",
       " 'n e c e s s ar i l yEND',\n",
       " 'r e e e e e e ea ll yEND',\n",
       " 'r ea a al yEND',\n",
       " 'r ea ll ll ll ll ll yEND',\n",
       " 'r l iEND',\n",
       " 'r ea ll i eEND',\n",
       " 'r ea ll ll l y y yEND',\n",
       " 'r e e l iEND',\n",
       " 'r 3 a ll yEND',\n",
       " 'r ea ll ll y yEND',\n",
       " 'r ea ll y - r ea ll yEND',\n",
       " 'r e l al yEND',\n",
       " 'r ea ll ll y y y yEND',\n",
       " 'r i ll iEND',\n",
       " 'r ea ll y r ea ll y r ea ll yEND',\n",
       " '- r ea ll y - END',\n",
       " 'r ea ll y y y y y yEND',\n",
       " 'r ea a ll y yEND',\n",
       " 'ea ll yEND',\n",
       " 'r e e ea a a ll yEND',\n",
       " 'r ea ll y r ea ll yEND',\n",
       " 'r e ea a ll yEND',\n",
       " 'r r ea ll yEND',\n",
       " 'r ea a a a ll l yEND',\n",
       " 'r ea ll u END',\n",
       " 'r ea a a a a a ll yEND',\n",
       " '/ r ea ll y / END',\n",
       " 'r ea l y yEND',\n",
       " 'r ea a ll l yEND',\n",
       " 'r ea ll ll ll ll l yEND',\n",
       " 'r ea ll ll y y yEND',\n",
       " 'r ea a a ll l yEND',\n",
       " 'w ea ll yEND',\n",
       " 'r e e e e e ea ll yEND',\n",
       " 'r ea ll l y y y yEND',\n",
       " 'r ell iEND',\n",
       " 'g en u in l yEND',\n",
       " 'r ea ll tEND',\n",
       " 'r ea ll i iEND',\n",
       " 'r ea ll l y yEND',\n",
       " 'r ea al yEND',\n",
       " 'r ea ll ll ll ll yEND',\n",
       " '_ r ea ll y _ END',\n",
       " 'r ea ll y y y y yEND',\n",
       " 'r ea ll y 2 END',\n",
       " 's h o l eEND',\n",
       " 'r ea a a a a ll yEND',\n",
       " 'r e e l yEND',\n",
       " 'r ell eEND',\n",
       " 'r ea ll l y y yEND',\n",
       " 's h o l END',\n",
       " 'r e ea ll yEND',\n",
       " 'r e e e e ea ll yEND',\n",
       " 'r ea ll ll ll l yEND',\n",
       " 'r i ll yEND',\n",
       " 'r ea ll y y y yEND',\n",
       " 'r ea a a a ll yEND',\n",
       " 'r ea a a ll yEND',\n",
       " 'r i l iEND',\n",
       " 'r e e ea ll yEND',\n",
       " 'r ea a ll yEND',\n",
       " 'r ea ll ll ll yEND',\n",
       " 'r e e e ea ll yEND',\n",
       " 'r ea ll y y yEND',\n",
       " 'r i l yEND',\n",
       " 's h o ll END',\n",
       " 'r ea l iEND',\n",
       " 'r e l iEND',\n",
       " 'r ea ll ll l yEND',\n",
       " 'r ell yEND',\n",
       " 'r ea ll iEND',\n",
       " 'r e l eEND',\n",
       " 'r ea ll y yEND',\n",
       " 'r ea ll ll yEND',\n",
       " 'r ea ll l yEND',\n",
       " 'r ll yEND',\n",
       " 'g en u in e l yEND',\n",
       " 'r ea l yEND',\n",
       " 'r ea ll yEND',\n",
       " 'r l yEND',\n",
       " 'al r e d a yEND',\n",
       " 'al r ea y dEND',\n",
       " 'f in al iEND',\n",
       " 'o f f i s h END',\n",
       " 'al r a d yEND',\n",
       " 'w oo d aEND',\n",
       " 'or e d iEND',\n",
       " 'al r ea a d yEND',\n",
       " 'al r ea d y y y y yEND',\n",
       " 'al r ea d d yEND',\n",
       " 'al ea d yEND',\n",
       " 'al r ea yEND',\n",
       " 's u c e s s f u ll yEND',\n",
       " 'al r e d iEND',\n",
       " 'ar ea d yEND',\n",
       " 'al r ea d iEND',\n",
       " 'al r ea d i iEND',\n",
       " 'al r ea dEND',\n",
       " 'al r ea d y y yEND',\n",
       " 'a w r ea d yEND',\n",
       " 'al r dEND',\n",
       " 'c u d aEND',\n",
       " 'al r e d yEND',\n",
       " 'a ll r ea d yEND',\n",
       " 'al r ea d y yEND',\n",
       " 'al r d yEND',\n",
       " 'p r e v i ou s l yEND',\n",
       " 'al r ea d yEND',\n",
       " 'r e c en t l yEND',\n",
       " '- al m o s tEND',\n",
       " 'n ea l yEND',\n",
       " 'n ea r ll yEND',\n",
       " 'al m 0 s tEND',\n",
       " 'al om o s tEND',\n",
       " 'al om s tEND',\n",
       " 'al m o st tEND',\n",
       " 'al m s o tEND',\n",
       " 'a m o s tEND',\n",
       " 'a ll m o s tEND',\n",
       " 'al m s tEND',\n",
       " 'a v er a g ingEND',\n",
       " 'r ou g h l yEND',\n",
       " 'v i r t u a ll yEND',\n",
       " 'a p p r o x i m a t e l yEND',\n",
       " 'p r a c t i c a ll yEND',\n",
       " 'al m o s tEND',\n",
       " 'n ea r l yEND',\n",
       " 's i b b yEND',\n",
       " 'c u r r en t yEND',\n",
       " 'o f f i c a i ll yEND',\n",
       " 'o f f c i a ll yEND',\n",
       " '# b g g p l a yEND',\n",
       " 'c u r en t l yEND',\n",
       " 'b u s i l yEND',\n",
       " 'o f f i c al yEND',\n",
       " 'o f i c i a ll yEND',\n",
       " 'c or d i a ll yEND',\n",
       " '< U R L - l i st en . g h e tt or a d i o . f m > END',\n",
       " '< U R L - k a i s er e g g . c h > END',\n",
       " 'h u c k l e b er r i e sEND',\n",
       " 'h e i s eEND',\n",
       " '# r ea d c a s tEND',\n",
       " 'p r e s en t l yEND',\n",
       " 'o f f i c i al yEND',\n",
       " '< U R L - g o . n i k e . c om > END',\n",
       " 'o f f i c a ll yEND',\n",
       " 'r e p or t e d l yEND',\n",
       " 'o f f i c i a ll yEND',\n",
       " 'c u r r en t l yEND',\n",
       " 'f in a ll l y yEND',\n",
       " 'f in a ll iEND',\n",
       " 'f in a ll l y y yEND',\n",
       " '# o f f i c i a ll yEND',\n",
       " 'f i i i in a ll yEND',\n",
       " 'f n a ll yEND',\n",
       " 'f in a ll y y y y yEND',\n",
       " 'f i in a ll yEND',\n",
       " '- f in a ll yEND',\n",
       " 'b er l yEND',\n",
       " 'f in a ll ll ll yEND',\n",
       " '# th ing s i d i d o v er th e s u m m erEND',\n",
       " '< U R L - m a p m y f i t n e s s . c om > END',\n",
       " 'f in a ll ll l yEND',\n",
       " 'f in i a ll yEND',\n",
       " 's n a c k f e e dEND',\n",
       " 'f in a ll y y y yEND',\n",
       " 'f in a ll ll yEND',\n",
       " 'f i an ll yEND',\n",
       " '< U R L - m a p m y r i d e . c om > END',\n",
       " 'f in a ll y y yEND',\n",
       " 's u c c e s f u ll yEND',\n",
       " 'f in a ll y yEND',\n",
       " '# m y f i t n e s s p al END',\n",
       " 'f in n a ll yEND',\n",
       " '< U R L - m a p m y r u n . c om > END',\n",
       " 'f in a ll l yEND',\n",
       " 'r e l u c t an t l yEND',\n",
       " 'f in n al yEND',\n",
       " '< U R L - c oo r d . in f o > END',\n",
       " 'f in al yEND',\n",
       " 'f in a ll yEND',\n",
       " 's u c c e s s f u ll yEND',\n",
       " 'k n o w e s tEND',\n",
       " 'r a th r END',\n",
       " 'c an s tEND',\n",
       " '< U R L - s u p er m ar k e t . c om > END',\n",
       " 'r a th aEND',\n",
       " 'r a th erEND',\n",
       " 's ha l tEND',\n",
       " \"d on t ' c h aEND\",\n",
       " 'i i on END',\n",
       " 'i m m oEND',\n",
       " '4 + 4 END',\n",
       " 'i i b END',\n",
       " 'i d on t tEND',\n",
       " 'b r in j al END',\n",
       " 'i d on END',\n",
       " 'th ell END',\n",
       " '2 iEND',\n",
       " 'n u s tEND',\n",
       " 'a b t aEND',\n",
       " 'l e y sEND',\n",
       " 'm e + y ou END',\n",
       " 'l e m m aEND',\n",
       " 's h ou l d sEND',\n",
       " 'w ell iEND',\n",
       " 'i / i iEND',\n",
       " 'd i d s tEND',\n",
       " '1 iEND',\n",
       " 'c ha r s e tEND',\n",
       " 'u l dEND',\n",
       " 'd / n END',\n",
       " 'í END',\n",
       " 'f . i . n . a . l . s .END',\n",
       " 'i o w n END',\n",
       " 'i i dEND',\n",
       " 'n on - v i r g in END',\n",
       " 's k y ha w k END',\n",
       " 's k y l an eEND',\n",
       " 'c h _ t y p eEND',\n",
       " 'k en o tEND',\n",
       " 'd in n yEND',\n",
       " '# i d on tEND',\n",
       " '- i iEND',\n",
       " '# y a m a m a e v erEND',\n",
       " '2 0 10 / 0 7 END',\n",
       " '2 0 10 / 0 5 END',\n",
       " 'c . l . a . s . s .END',\n",
       " '& iEND',\n",
       " 'i f u END',\n",
       " 'f m tEND',\n",
       " 'th a t iEND',\n",
       " 'l e m iEND',\n",
       " '# m y g o al f or 2 0 1 2 END',\n",
       " 'y u dEND',\n",
       " 'e b u END',\n",
       " 'b o tt aEND',\n",
       " 'm on e y - b a c k END',\n",
       " '1 9 tEND',\n",
       " 'i 8 END',\n",
       " '# on l y f a t p e o p l eEND',\n",
       " '# th ing s i a in t d on e y e tEND',\n",
       " 'd on t c h u END',\n",
       " 's g eEND',\n",
       " 'i f iEND',\n",
       " 'i l dEND',\n",
       " '# c on f u s ing th ing s g i r l s d oEND',\n",
       " '_ i _ END',\n",
       " 'm u z END',\n",
       " 'c an iEND',\n",
       " '# u r g i r l f r i en d e v erEND',\n",
       " 'i - i - iEND',\n",
       " '# on l y u g l y p e o p l eEND',\n",
       " '2 0 10 / 1 2 END',\n",
       " 'l e tt sEND',\n",
       " 'n e erEND',\n",
       " '2 0 10 / 10 END',\n",
       " '2 0 10 / 0 4 END',\n",
       " 'c y a aEND',\n",
       " 's on tEND',\n",
       " '2 0 10 / 0 8 END',\n",
       " 'd on n END',\n",
       " '2 0 10 / 0 6 END',\n",
       " 'a p t - g e tEND',\n",
       " 'u on END',\n",
       " 'd o an END',\n",
       " 'd o s tEND',\n",
       " '# on l y w h i t e p e o p l eEND',\n",
       " 'i i i iEND',\n",
       " '# th ing s b l a c k p e o p l e d oEND',\n",
       " 'i d w END',\n",
       " '2 + 2 END',\n",
       " 'in eEND',\n",
       " 'ha s tEND',\n",
       " 'i d i d n tEND',\n",
       " '1 + 1 END',\n",
       " 'h e dEND',\n",
       " 'p r o v o k ingEND',\n",
       " 'i d n tEND',\n",
       " 'u l END',\n",
       " 'u m aEND',\n",
       " 'w dEND',\n",
       " 'u dEND',\n",
       " 'i i iEND',\n",
       " 'll END',\n",
       " 'i v END',\n",
       " 'i on END',\n",
       " 'i iEND',\n",
       " 'i dEND',\n",
       " 'p r a c t i c al yEND',\n",
       " 'u s s u a ll yEND',\n",
       " 'a c c i d en t i a ll yEND',\n",
       " 's u d en l yEND',\n",
       " 't ea r f u ll yEND',\n",
       " 'u s u a ll l yEND',\n",
       " 'n a i v e l yEND',\n",
       " 'r e f l e x i v e l yEND',\n",
       " 'o p t i on a ll yEND',\n",
       " 'l i k e 2 END',\n",
       " 'c on t in u o s l yEND',\n",
       " 'u n w i s e l yEND',\n",
       " 'p r a c t i c l yEND',\n",
       " 'a t u a ll yEND',\n",
       " 'a c t l yEND',\n",
       " 'p u r p o s l yEND',\n",
       " 's e c r e t e l yEND',\n",
       " 'ha r d l e yEND',\n",
       " 'a u t om a t i c al yEND',\n",
       " 'c on c e i v a b l yEND',\n",
       " 'a b s en t m in d e d l yEND',\n",
       " 'a c t u a ll iEND',\n",
       " 'l i t r a ll yEND',\n",
       " 's u b c on c i ou s l yEND',\n",
       " 'c on st an l yEND',\n",
       " 'l i t er l yEND',\n",
       " 'd o in tEND',\n",
       " 'm a k e m END',\n",
       " 's u p p o s e l yEND',\n",
       " 'a c t u a ll y yEND',\n",
       " 'a c t u l yEND',\n",
       " 'g o an n aEND',\n",
       " 'b a s c i a ll yEND',\n",
       " 'p r a t i c a ll yEND',\n",
       " 'i i v eEND',\n",
       " 's u p p o s a b l yEND',\n",
       " 'b a s i c al yEND',\n",
       " 'er r on e ou s l yEND',\n",
       " 'f l a t l yEND',\n",
       " 'c a s j END',\n",
       " 'l e g i t l yEND',\n",
       " 'l i tt er l yEND',\n",
       " 'm u s s yEND',\n",
       " 'or g in a ll yEND',\n",
       " 'd on r END',\n",
       " 'in a d v er t an t l yEND',\n",
       " 'a c t a ll yEND',\n",
       " 'a c t u al iEND',\n",
       " 'u s u s a ll yEND',\n",
       " 'a c c u a ll yEND',\n",
       " 'in t u i t i v e l yEND',\n",
       " 'a u t om a t i c l yEND',\n",
       " 'g r u d g ing l yEND',\n",
       " 'b e g r u d g ing l yEND',\n",
       " 's c ar c e l yEND',\n",
       " 'b ar l yEND',\n",
       " 'l i tt er al yEND',\n",
       " 'b l a t en t l yEND',\n",
       " 'ha b i t u a ll yEND',\n",
       " 'or d in ar i l yEND',\n",
       " 'a f f e c t i on a t e l yEND',\n",
       " 's n ea k i l yEND',\n",
       " 'a c c i d en t al yEND',\n",
       " 'n or m al yEND',\n",
       " 's ing l e h an d e d l yEND',\n",
       " 'c om p u l s i v e l yEND',\n",
       " 's u b l i m in a ll yEND',\n",
       " 'in v o l u n t ar i l yEND',\n",
       " 'a c t u a ll l yEND',\n",
       " 'g in eEND',\n",
       " 'd e f in i t i v e l yEND',\n",
       " 'u s u al yEND',\n",
       " 'l i t er al yEND',\n",
       " 'b r a v e l yEND',\n",
       " 'a c c t u a ll yEND',\n",
       " 'a c u a ll yEND',\n",
       " 'b a s i c l yEND',\n",
       " 'ha f f END',\n",
       " 'in st in c t i v e l yEND',\n",
       " 'u n c on s c i ou s l yEND',\n",
       " 's ing l e - h an d e d l yEND',\n",
       " 's l y l yEND',\n",
       " 'a c t a u ll yEND',\n",
       " 'd r u n k en l yEND',\n",
       " 'a c u t a ll yEND',\n",
       " 'f oo l i s h l yEND',\n",
       " 'b ea r l yEND',\n",
       " 'p u r p o s e f u ll yEND',\n",
       " 'j o k ing l yEND',\n",
       " 'r ou t in e l yEND',\n",
       " 'k n o w ing l yEND',\n",
       " 's u b c on s c i ou s l yEND',\n",
       " 'u n k n o w ing l yEND',\n",
       " 'a c t u ll yEND',\n",
       " 'm i r a c u l ou s l yEND',\n",
       " 'l i tt er a ll yEND',\n",
       " 'c o ll e c t i v e l yEND',\n",
       " 't r a d i t i on a ll yEND',\n",
       " 'in a d v er t en t l yEND',\n",
       " 'm i st a k en l yEND',\n",
       " 'v o l u n t ar i l yEND',\n",
       " 'b l in d l yEND',\n",
       " 'in d i r e c t l yEND',\n",
       " 's p on t an e ou s l yEND',\n",
       " 'w i ll ing l yEND',\n",
       " 'h er e b yEND',\n",
       " 'g r a d u a ll yEND',\n",
       " 'a c t u al yEND',\n",
       " 'j e sEND',\n",
       " 'd e l i b er a t e l yEND',\n",
       " 'c on t in u ou s l yEND',\n",
       " 's e l d om END',\n",
       " 'in t en t i on a ll yEND',\n",
       " 'p u r p o s e l yEND',\n",
       " 'b ar l e yEND',\n",
       " 'in i t i a ll yEND',\n",
       " 'a c t i v e l yEND',\n",
       " 'on tEND',\n",
       " 'c a s u a ll yEND',\n",
       " 'e s s en t i a ll yEND',\n",
       " 'p r ou d l yEND',\n",
       " 't y p i c a ll yEND',\n",
       " 'a c c i d en t l yEND',\n",
       " 'm a g i c a ll yEND',\n",
       " 'a ll e g e d l yEND',\n",
       " 's u p p o s e d l yEND',\n",
       " 'or i g in a ll yEND',\n",
       " 's e c r e t l yEND',\n",
       " 'g en er a ll yEND',\n",
       " 'r ar e l yEND',\n",
       " 'a u t om a t i c a ll yEND',\n",
       " 'a c c i d en t a ll yEND',\n",
       " 'r an d om l yEND',\n",
       " 'n or m a ll yEND',\n",
       " 'c on st an t l yEND',\n",
       " 'ha r d l yEND',\n",
       " 'b ar e l yEND',\n",
       " 'b a s i c a ll yEND',\n",
       " 'l i t er a ll yEND',\n",
       " 'a c t u a ll yEND',\n",
       " 'u s u a ll yEND',\n",
       " 's u d d en t l yEND',\n",
       " '- al w a y sEND',\n",
       " 'al o sEND',\n",
       " 'c o in c i d en t l yEND',\n",
       " 'p r a y er f u ll yEND',\n",
       " 'd e m on b r u en END',\n",
       " 'd e s p ar a t e l yEND',\n",
       " 'g i e sEND',\n",
       " 'd e s p er a t l yEND',\n",
       " 'a s l oEND',\n",
       " 'al t er n a t e l yEND',\n",
       " 'b e l a t e d l yEND',\n",
       " 'j x END',\n",
       " 's u b s e q u en t l yEND',\n",
       " 's in c er l yEND',\n",
       " 'h en c e f or th END',\n",
       " 'u l t i m a t e l yEND',\n",
       " 'd e s p er a t e l yEND',\n",
       " 's in c er e l yEND',\n",
       " 's u d d en l yEND',\n",
       " 'al s oEND',\n",
       " 'o b i ou s l yEND',\n",
       " 'd ea d a z z END',\n",
       " 'e v i d en t a ll yEND',\n",
       " 't o t a ll y y yEND',\n",
       " 's r i ou s l yEND',\n",
       " 'o b v i ou l s yEND',\n",
       " 'o b v s l yEND',\n",
       " 's er o i u s l yEND',\n",
       " 'n e v er r r r r r r END',\n",
       " 's er i s ou l yEND',\n",
       " 'h on e st l y yEND',\n",
       " 's r l s yEND',\n",
       " 's er i ou s l y y y yEND',\n",
       " 'l i t er a ll l yEND',\n",
       " 'o b v i o s l yEND',\n",
       " 'o v i ou s l yEND',\n",
       " 'g o tt c h aEND',\n",
       " 'o b v z END',\n",
       " 'd / aEND',\n",
       " 'w i s h iEND',\n",
       " 'g o t c ha aEND',\n",
       " 'i i i i i i i i iEND',\n",
       " '# j u st c a u s e w e c oo l END',\n",
       " \"s or r y ' sEND\",\n",
       " 'l i k e e e e e eEND',\n",
       " 's h e e e eEND',\n",
       " 'g o t c h y aEND',\n",
       " 's r l yEND',\n",
       " 'f er r ea l END',\n",
       " 's er i ou s l y y yEND',\n",
       " 's i r i u s l yEND',\n",
       " 'g e z END',\n",
       " 'n e v er r r r r r END',\n",
       " 'l o k e yEND',\n",
       " 's u r l e yEND',\n",
       " 's er i ou s ll yEND',\n",
       " 'h on e s l t yEND',\n",
       " 's er i u o s l yEND',\n",
       " 'd ea d a s s sEND',\n",
       " 'l o w k e y yEND',\n",
       " '- r ea ll yEND',\n",
       " 's er i u s l yEND',\n",
       " 's er i ou l yEND',\n",
       " 'b e t c h u END',\n",
       " 's er ou s l yEND',\n",
       " 's er z l yEND',\n",
       " 'h i g h k e yEND',\n",
       " 'n e v er r r r r END',\n",
       " 's er i o s l yEND',\n",
       " 'l i k e e e e eEND',\n",
       " 's er i ou l s yEND',\n",
       " 's er i o s u l yEND',\n",
       " 'p er s on al yEND',\n",
       " 'u n d er st an d a b l yEND',\n",
       " 'u n n oEND',\n",
       " 's er i ou s l y yEND',\n",
       " 'g e d d i tEND',\n",
       " 'l i k e e e eEND',\n",
       " 'th e or e t i c a ll yEND',\n",
       " 'd . aEND',\n",
       " 'r ea l i st i c a ll yEND',\n",
       " 'o b v iEND',\n",
       " 't r u th f u ll yEND',\n",
       " 'o b v sEND',\n",
       " 'b e t c h aEND',\n",
       " '# l o w k e yEND',\n",
       " 'o b v END',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preform_bpe(brown_df, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9888b25499797c4fb0fd4f13646b0c3c",
     "grade": false,
     "grade_id": "cell-7d1e49878db56df4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Jakie angielskie słowo jako pierwsze dostało swój własny token?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df4c7b8b5aa2b077eaa2d42429797139",
     "grade": true,
     "grade_id": "cell-acd48c77e2c1bcec",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "Odnosząc się do słów jest to the - 30 iteracja (to - 32 iteracja - jednakże może dotyczyć to tylko samych końcówek), jednakże token związany z zwróceniem się do kogoś w Tweecie (tj. <@MENTION>), została wygenerowany jeszcze wcześniej - 27 iteracja. Można też zauważyć że jeszcze szybciej tworzy się końcówka dla formy gerund (ing) - 18 iteracja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd51e6fc0cd1d3b4d8b9e9a2fa1b0316",
     "grade": false,
     "grade_id": "cell-df60f5e5c6fe4ca0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Jakie są zalety korzystania z tokenizacji BPE w kontekście tworzenia reprezentacji (problem OOV, odnieś się do  k-gramów i n-gramów)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64306e36b58f1eee12c8bb339123e105",
     "grade": true,
     "grade_id": "cell-006ef6fd3e397206",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<div style=\"color: red\"> YOUR ANSWER HERE</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2 - klasyfikacja (15 pkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy kod powinien wczytać i ztokenizować zbiór danych dot. analizy wydźwięku. Jeśli nie masz biblioteki `nltk` musisz ją zainstalować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import DataSet\n",
    "training_set = DataSet(['tweets.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajdziesz przykład odczytu jednego tweeta z obiektu DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in training_set.tweets:\n",
    "    print(i.text)\n",
    "    print(i.tokens)\n",
    "    print(i.clazz)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Systemy IL często pracują z bardzo dużą liczbą cech, które są rzadkie np. cechy Bag-Of-Words, cechy n-gramowe itd. Powoduje to że klasyczna macierz przykłady uczące na cechy rośnie do bardzo dużych rozmiarów nawet dla małych zbiorów uczących (w sensie liczby przykładów). Ponadto samo przechowywanie w pamięci słownika mapującego konkretne słowa/n-gramy na indeksy kolumn macierzy może być bardzo kosztowne pamięciowo przy dużych rozmiarach słownika.\n",
    "\n",
    "Istnieje jednak technika, która pozwala nam na ominięcie tej przeszkody: haszowanie cech. Opis tej techniki znajdziesz na stronie:  https://en.wikipedia.org/wiki/Feature_hashing Jest ona też implementowana w obiekcie `sklearn.feature_extraction.FeatureHasher`. Zapoznaj się z opisem techniki i wykonaj poniższe polecenia.\n",
    "\n",
    "- Wykorzystując haszowanie cech wytrenuj wybrany klasyfikator na zbiorze uczącym dla cech Bag-of-words (możesz też spróbować cechy n-gramowe). Możesz wykorzystać gotową tokenizację we właściwości `.tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac05ad71ee90b1c800030849c5321cb7",
     "grade": true,
     "grade_id": "cell-f6cfe39258fbec51",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd6bcaf8dae7184b60bd9a8adadd85d8",
     "grade": false,
     "grade_id": "cell-1caf16c401c91ef2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Stwórz wykres zależności wybranej miary klasyfikacji od wymiarów macierzy danych (chodzi o liczbę cech do których haszujemy cechy oryginalne). Wystarczy przetestować kilka (>=4) wybranych wartości na skali logarytmicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bd253bac561b269cff3a3dceadc70f0",
     "grade": true,
     "grade_id": "cell-8076c16242981ae9",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82f3f52a6fe2a10a300b5d45101b32b5",
     "grade": false,
     "grade_id": "cell-eab7c2a5f0251ff4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    " - Obserwując stworzony wykres - skomentuj. Jak dużo jakości klasyfikacji się traci (albo zyskuje?) korzystając z mniejszej liczby haszowanych cech? Często klasyfikatory bardzo dobrze działają nawet przy liczbie haszowanych cech dla których na pewno istnieją konflikty cech oryginalnych - jak myślisz dlaczego? (Pomyśl o interpretacji takich skonfliktowanych cech)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed30f2d487da41cf1a92ffb63195d621",
     "grade": true,
     "grade_id": "cell-2caea1821af5d8aa",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<div style=\"color: red\"> YOUR ANSWER HERE</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20139da166319b49eea5cc7e984fc08e",
     "grade": false,
     "grade_id": "cell-0d86672dbabbf54d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    " - W poprzednim zadaniu wczytałeś wynik grupowania Browna do pamięci. Wytrenuj klasyfikator na reprezentacji ,,Bag-of-clusters'' tj. w kolumnach zamiast słów/n-gramów będziesz miał grupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b13c0457af5dab17e12780eafb1c5ac4",
     "grade": true,
     "grade_id": "cell-55264f6fe514d007",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e47a053ebc12ac2fd97d9c11187da9b",
     "grade": false,
     "grade_id": "cell-493071698fc0205e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Podsumuj eksperymenty: poznałeś dwie możliwości ograniczenia liczby cech - zastąpienie słów ich grupami i haszowanie cech. Jakie są wady i zalety obydwu podejść?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b80ace505afba9b12fd5d3896a9046ef",
     "grade": true,
     "grade_id": "cell-4508400659f7243e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<div style=\"color: red\"> YOUR ANSWER HERE</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
