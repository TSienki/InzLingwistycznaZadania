{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Inżynieria-lingwistyczna\" data-toc-modified-id=\"Inżynieria-lingwistyczna-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Inżynieria lingwistyczna</a></span></li><li><span><a href=\"#Zadanie-1---tokenizacja-(12-pkt)\" data-toc-modified-id=\"Zadanie-1---tokenizacja-(12-pkt)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Zadanie 1 - tokenizacja (12 pkt)</a></span></li><li><span><a href=\"#Zadanie-2---klasyfikacja-(15-pkt)\" data-toc-modified-id=\"Zadanie-2---klasyfikacja-(15-pkt)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Zadanie 2 - klasyfikacja (15 pkt)</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inżynieria lingwistyczna\n",
    "Ten notebook jest oceniany półautomatycznie. Nie twórz ani nie usuwaj komórek - struktura notebooka musi zostać zachowana. Odpowiedź wypełnij tam gdzie jest na to wskazane miejsce - odpowiedzi w innych miejscach nie będą sprawdzane (nie są widoczne dla sprawdzającego w systemie).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1 - tokenizacja (12 pkt)\n",
    "\n",
    "Jedną z nowoczesnych technik tokenizacji jest BPE - byte-pair encoding [1]. Technika ta polega na podzielenie słów na częste podsłowa (morfemy). W przeciwieństwie do podejść lingwistycznych, wymagających reguł tworzenia morfemów, BPE wyznacza je automatycznie poprzez wyznaczenie najczęstszych przylegających do siebie sekwencji znaków które występują obok siebie.\n",
    "\n",
    "Algorytm przebiega w następujących krokach.\n",
    "1. Podziel wszystkie słowa na symbole (początkowo pojedyncze znaki)\n",
    "2. Wyznacz najczęściej występującą obok siebie parę symboli \n",
    "3. Stwórz nowy symbol będący konkatenacją dwóch najczęstszych symboli.\n",
    "\n",
    "Uwaga 1: każde słowo zakończone jest specjalnym symbolem końca wyrazu.\n",
    "\n",
    "Uwaga 2: tworzenie nowego symbolu nie powoduje usuniecie starego tj. zawsze jednym z możliwych symboli jest pojedynczy znak, ale jeśli można to stosujemy symbol dłuższy.\n",
    "\n",
    "Przykład: korpus w którym występuje ,,ala'' 5 razy i ,,mama 10 razy''\n",
    "1. Dzielimy słowa na symbole ,,a l a END'' ,,m a m a END''  gdzie END jest symbolem końca wyrazu.\n",
    "2. Najczęstsza para obok siebie to ,,m a'' (20) razy\n",
    "3. Nowy symbol ,,ma''\n",
    "4. Nowy podział ,,a l a END'' ,,ma ma END''\n",
    "5. Najczęstsza para ,,ma ma'' (10) razy\n",
    "6. Nowy symbol ,,mama''\n",
    "7. Nowy podział ,,a l a END'' ,,mama END''\n",
    "8. itd.\n",
    "\n",
    "W pliku ,,brown_clusters.tsv'' pierwsza kolumna to identyfikator skupienia (nie używamy w tym zadaniu), druga kolumna to wyrazy, a trzecia to ich liczności w pewnym korpusie tweetów. Zaimplementuj technike BPE na tych słowach.\n",
    "\n",
    "Zaimplementuj algorytm BPE wykonujący `number_of_iterations` iteracji (łączeń symboli).\n",
    "\n",
    "[1] Sennrich, R., Haddow, B., and Birch, A. (2016). Neural machine translation of rare words with subword units. In ACL 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T20:42:37.786118Z",
     "start_time": "2020-03-22T20:42:36.017184Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ff3b90528fdb50de90c5c946c157e21",
     "grade": false,
     "grade_id": "cell-93d78a28d4e25cbc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "brown_df = pd.read_csv('brown_clusters.tsv', sep='\\t', header=0, names=['cluster', 'word', 'count'])\n",
    "\n",
    "number_of_iterations = 10\n",
    "import math\n",
    "def preform_bpe(brown_df, number_of_iterations):\n",
    "    \"\"\"\n",
    "    Funckcja przyjmuje ramkę w formacie analogicznym do obiektu brown_df (wczytany wyżej)\n",
    "     oraz liczbę iteracji.\n",
    "    Wyjściem funkcji powinna być lista słów z poszczególnymi tokenami/symbolami oddzielonymi spacją.\n",
    "    Za znak końca wyrazu przyjmij END. \n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    class Counter(dict):\n",
    "         def __missing__(self, key):\n",
    "            return 0\n",
    "    \n",
    "    last_word = \"\"\n",
    "    # Deal with words interpeted as nan. The best option would be change pd.read_csv function, but i dunno how it will be tested. \n",
    "    brown_df[\"word\"] = brown_df[\"word\"].apply(lambda word: \"nan\" if isinstance(word, float) and math.isnan(word) else word)\n",
    "    split_words = [list(word) + [\"END\"] for word in brown_df[\"word\"] if not isinstance(word, float) or not math.isnan(word)]\n",
    "    words_count = list(brown_df[\"count\"])\n",
    "    for i in range(number_of_iterations):\n",
    "        pairs = Counter()\n",
    "        # generate pairs\n",
    "        for split_word, count in zip(split_words, words_count):\n",
    "            for pair in zip(split_word[:-1], split_word[1:]):\n",
    "                pairs[pair] += count\n",
    "        biggest_pair = max(pairs, key=pairs.get)\n",
    "#         print(i, biggest_pair)\n",
    "        joined_biggest_pair = \"\".join(biggest_pair)\n",
    "        new_split_words = []\n",
    "        \n",
    "        # generate new split words \n",
    "        for split_word in split_words:\n",
    "            new_split_word = []\n",
    "            matched_in_last_iteration = False\n",
    "            for pair in zip(split_word[:-1], split_word[1:]):\n",
    "                if pair == biggest_pair and not matched_in_last_iteration:\n",
    "                    new_split_word.append(joined_biggest_pair)\n",
    "                    matched_in_last_iteration = True\n",
    "                    continue \n",
    "                elif not matched_in_last_iteration:\n",
    "                    new_split_word.append(pair[0])\n",
    "                matched_in_last_iteration = False\n",
    "            if not matched_in_last_iteration:\n",
    "                new_split_word.append(pair[1])\n",
    "            new_split_words.append(new_split_word)\n",
    "        split_words = new_split_words\n",
    "    \n",
    "    return [\" \".join(split_word) for split_word in split_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test implementacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T20:42:38.288080Z",
     "start_time": "2020-03-22T20:42:38.273064Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfff70f711bf389f0f1cd969e7c3a413",
     "grade": true,
     "grade_id": "cell-7e952fa8dcd136fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_list_equal\n",
    "data = {'cluster': range(2), 'word':['ala', 'mama'], 'count': [5,10]}\n",
    "df = pd.DataFrame (data, columns = ['cluster', 'word', 'count'])\n",
    "vocab = preform_bpe(df, 1)\n",
    "assert_list_equal(vocab, ['a l a END', 'ma ma END'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spraw aby Twoja implementacja wypisywała kolejne łączone ze sobą symbole i uruchom Twoją funkcję na np. 50 iteracji, obserwując jakie tokeny są tworzone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:05:57.254503Z",
     "start_time": "2020-03-22T18:04:59.888082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('e', 'END')\n",
      "1 ('t', 'END')\n",
      "2 ('s', 'END')\n",
      "3 ('i', 'n')\n",
      "4 ('t', 'h')\n",
      "5 ('d', 'END')\n",
      "6 ('y', 'END')\n",
      "7 ('.', 'END')\n",
      "8 ('o', 'END')\n",
      "9 ('r', 'END')\n",
      "10 ('a', 'n')\n",
      "11 ('>', 'END')\n",
      "12 ('o', 'n')\n",
      "13 ('o', 'u')\n",
      "14 ('g', 'END')\n",
      "15 ('a', 'END')\n",
      "16 ('l', 'END')\n",
      "17 ('in', 'gEND')\n",
      "18 ('<', '@')\n",
      "19 ('<@', 'M')\n",
      "20 ('<@M', 'E')\n",
      "21 ('<@ME', 'N')\n",
      "22 ('<@MEN', 'T')\n",
      "23 ('<@MENT', 'I')\n",
      "24 ('<@MENTI', 'O')\n",
      "25 ('<@MENTIO', 'N')\n",
      "26 ('<@MENTION', '>END')\n",
      "27 ('r', 'e')\n",
      "28 ('i', 'END')\n",
      "29 ('th', 'eEND')\n",
      "30 ('e', 'n')\n",
      "31 ('o', 'm')\n",
      "32 ('t', 'oEND')\n",
      "33 (',', 'END')\n",
      "34 ('!', 'END')\n",
      "35 ('e', 'r')\n",
      "36 ('h', 'a')\n",
      "37 ('e', 'rEND')\n",
      "38 ('i', 't')\n",
      "39 (':', 'END')\n",
      "40 ('y', 'ou')\n",
      "41 ('a', 'r')\n",
      "42 ('a', 'l')\n",
      "43 ('o', 'r')\n",
      "44 ('o', 'w')\n",
      "45 ('.', '.END')\n",
      "46 ('s', 't')\n",
      "47 ('k', 'END')\n",
      "48 ('i', 'sEND')\n",
      "49 ('f', 'END')\n"
     ]
    }
   ],
   "source": [
    "preform_bpe(brown_df, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9888b25499797c4fb0fd4f13646b0c3c",
     "grade": false,
     "grade_id": "cell-7d1e49878db56df4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Jakie angielskie słowo jako pierwsze dostało swój własny token?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df4c7b8b5aa2b077eaa2d42429797139",
     "grade": true,
     "grade_id": "cell-acd48c77e2c1bcec",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Odnosząc się do słów są to article a - 16 iteracja i the - 30 iteracja (to - 32 iteracja - jednakże może dotyczyć to tylko samych końcówek), jednakże token związany z zwróceniem się do kogoś w Tweecie (tj. <@MENTION>), została wygenerowany jeszcze wcześniej - 27 iteracja. Można też zauważyć że jeszcze szybciej tworzy się końcówka dla formy gerund (ing) - 18 iteracja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd51e6fc0cd1d3b4d8b9e9a2fa1b0316",
     "grade": false,
     "grade_id": "cell-df60f5e5c6fe4ca0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Jakie są zalety korzystania z tokenizacji BPE w kontekście tworzenia reprezentacji (problem OOV, odnieś się do  k-gramów i n-gramów)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64306e36b58f1eee12c8bb339123e105",
     "grade": true,
     "grade_id": "cell-006ef6fd3e397206",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Tokenizacja BPE jest odporna na problem OOV, gdyż każde słowo można stworzyć z pojedyńczych znaków (które prawdopodobnie zostaną jako tokeny jeżeli liczba iteracji nie będzie zbyt duża), bądź ze zbitków znaków z innych tokenów.  \n",
    "\n",
    "Kompresuje zbiór - jest to de facto zbiór kompresujący. \n",
    "\n",
    "Tokenizacja BPE przy n-gramach może mieć mniej sensu niż tokenizacja zwykła, jeżeli te n-gramy będą małe (unigramy, trigramy), gdyż przy normalnych 3-gramach bierzemy 3 słowa które razem już mogą mieć jakiś sens, w wypadku tokenizacji dla słów rzadkich, na jedno słow mogą skłądać się 3 zbitki liter - tokeny raz mogą być słowa o pełnym znaczeniu w innych wypadkach nie. \n",
    "Ale może to mieć pozytywne skutki, dla tego modelu, gdyż możemy zyskać np. na sensie stopniowania para tokenów przymiotnika z końcówkami \"est\" \"er\" może dać nam informacje o stopniu przymiotnika.\n",
    "\n",
    "Wykorzystywanie tokenizacji (BPE i innych) nie ma sensu przy k-gramach, gdyż k-gramy biorą jako kontext k kolejnych znaków, a nie tokenów.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2 - klasyfikacja (15 pkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy kod powinien wczytać i ztokenizować zbiór danych dot. analizy wydźwięku. Jeśli nie masz biblioteki `nltk` musisz ją zainstalować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:11:47.112090Z",
     "start_time": "2020-03-22T18:11:35.440572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data set ['tweets.txt']\n"
     ]
    }
   ],
   "source": [
    "from helpers import DataSet\n",
    "training_set = DataSet(['tweets.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajdziesz przykład odczytu jednego tweeta z obiektu DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:11:47.289042Z",
     "start_time": "2020-03-22T18:11:47.283033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.\n",
      "['dear', '@microsoft', 'the', 'newooffice', 'for', 'mac', 'is', 'great', 'and', 'all', ',', 'but', 'no', 'lync', 'update', '?', \"c'mon\", '.']\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "for i in training_set.tweets:\n",
    "    print(i.text)\n",
    "    print(i.tokens)\n",
    "    print(i.clazz)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Systemy IL często pracują z bardzo dużą liczbą cech, które są rzadkie np. cechy Bag-Of-Words, cechy n-gramowe itd. Powoduje to że klasyczna macierz przykłady uczące na cechy rośnie do bardzo dużych rozmiarów nawet dla małych zbiorów uczących (w sensie liczby przykładów). Ponadto samo przechowywanie w pamięci słownika mapującego konkretne słowa/n-gramy na indeksy kolumn macierzy może być bardzo kosztowne pamięciowo przy dużych rozmiarach słownika.\n",
    "\n",
    "Istnieje jednak technika, która pozwala nam na ominięcie tej przeszkody: haszowanie cech. Opis tej techniki znajdziesz na stronie:  https://en.wikipedia.org/wiki/Feature_hashing Jest ona też implementowana w obiekcie `sklearn.feature_extraction.FeatureHasher`. Zapoznaj się z opisem techniki i wykonaj poniższe polecenia.\n",
    "\n",
    "- Wykorzystując haszowanie cech wytrenuj wybrany klasyfikator na zbiorze uczącym dla cech Bag-of-words (możesz też spróbować cechy n-gramowe). Możesz wykorzystać gotową tokenizację we właściwości `.tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:11:55.219109Z",
     "start_time": "2020-03-22T18:11:47.462035Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac05ad71ee90b1c800030849c5321cb7",
     "grade": true,
     "grade_id": "cell-f6cfe39258fbec51",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import random\n",
    "\n",
    "TEST_SET_SPLIT = 0.2\n",
    "n_features=100000\n",
    "random.seed(10)\n",
    "random.shuffle(training_set.tweets)\n",
    "\n",
    "tokens_test = [tweet.tokens for tweet in training_set.tweets[:int(len(training_set.tweets) * TEST_SET_SPLIT)]]\n",
    "y_test = [tweet.clazz for tweet in training_set.tweets[:int(len(training_set.tweets) * TEST_SET_SPLIT)]]\n",
    "tokens_train = [tweet.tokens for tweet in training_set.tweets[int(len(training_set.tweets) * TEST_SET_SPLIT):]]\n",
    "y_train = [tweet.clazz for tweet in training_set.tweets[int(len(training_set.tweets) * TEST_SET_SPLIT):]]\n",
    "\n",
    "\n",
    "def fit_and_evaluate_model_fe(n_features, tokens_train, y_train, tokens_test, y_test):    \n",
    "    fh = FeatureHasher(n_features=n_features, input_type=\"string\")\n",
    "    X_train = fh.transform(tokens_train)\n",
    "    X_test = fh.transform(tokens_test)\n",
    "    \n",
    "    clf = SVC(kernel=\"linear\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_predict = clf.predict(X_test)\n",
    "        \n",
    "    acc = accuracy_score(y_test, y_predict)\n",
    "    f1 = f1_score(y_test, y_predict, average=\"macro\")\n",
    "    return clf, acc, f1\n",
    "\n",
    "clf, acc, f1 = fit_and_evaluate_model_fe(n_features, tokens_train, y_train, tokens_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd6bcaf8dae7184b60bd9a8adadd85d8",
     "grade": false,
     "grade_id": "cell-1caf16c401c91ef2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Stwórz wykres zależności wybranej miary klasyfikacji od wymiarów macierzy danych (chodzi o liczbę cech do których haszujemy cechy oryginalne). Wystarczy przetestować kilka (>=4) wybranych wartości na skali logarytmicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:12:39.224093Z",
     "start_time": "2020-03-22T18:11:55.450039Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bd253bac561b269cff3a3dceadc70f0",
     "grade": true,
     "grade_id": "cell-8076c16242981ae9",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5059578368469294, f1: 0.22398052343274497\n",
      "Acc: 0.5224564619615032, f1: 0.35716156406598637\n",
      "Acc: 0.538038496791934, f1: 0.4723241376913461\n",
      "Acc: 0.5334555453712191, f1: 0.4895176958055036\n",
      "Acc: 0.5609532538955087, f1: 0.5127693955229952\n",
      "Acc: 0.5609532538955087, f1: 0.5079923064238595\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def generate_plot(n_values):\n",
    "    accs, f1s = [], []\n",
    "    n_values = [10 ** n for n in n_values]\n",
    "    for n in n_values:\n",
    "        clf, acc, f1 = fit_and_evaluate_model_fe(n, tokens_train, y_train, tokens_test, y_test)\n",
    "        print(f\"Acc: {acc}, f1: {f1}\")\n",
    "        accs.append(acc) \n",
    "        f1s.append(f1)\n",
    "        \n",
    "    fig = plt.figure(figsize = [10, 6])\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(n_values, accs, label=\"accuracy\")\n",
    "    ax.plot(n_values, f1s, label=\"f1\")\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_xscale('log', basex=10)\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Zależność miar oceny od ilości cech\")\n",
    "    ax.set_xlabel(\"Ilość cech do których hashujemy\")\n",
    "    ax.set_ylabel(\"Miara oceny\")\n",
    "    plt.show()\n",
    "    \n",
    "generate_plot(list(range(1, 7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82f3f52a6fe2a10a300b5d45101b32b5",
     "grade": false,
     "grade_id": "cell-eab7c2a5f0251ff4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    " - Obserwując stworzony wykres - skomentuj. Jak dużo jakości klasyfikacji się traci (albo zyskuje?) korzystając z mniejszej liczby haszowanych cech? Często klasyfikatory bardzo dobrze działają nawet przy liczbie haszowanych cech dla których na pewno istnieją konflikty cech oryginalnych - jak myślisz dlaczego? (Pomyśl o interpretacji takich skonfliktowanych cech)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed30f2d487da41cf1a92ffb63195d621",
     "grade": true,
     "grade_id": "cell-2caea1821af5d8aa",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Jak można zauważyć trafność klasyfikatora jest przaktycznie nie różni się w zależności od liczby cech które hashujemy. Jednakże zmienia się miara f-score zmienia się już w zależności od liczby cech. Dla małej wartości przyjmuję ona mniejsze wartości (~0.22) i zwiększa się (do ok. 0.5) przy 1000 cech, później miara ta utrzymuje się na podobnej wartości. Hashowanie mniejszej ilości cech niż 10 nie ma sensu, gdyż traci się za dużo informacji z tekstu. Przy za dużej ilości może dojść do momentu gdy cech \"featerów\" będzie więcej niż słów unikalnych w tekście. Również przy zwiększaniu ilości cech traic się niewrażliwość na pomyłki  \n",
    "\n",
    "Kalsyfikator działa dobrze nawet przy liczbie cech dla których na pewno istnieją konflikty cech oryginalnych, gdyż jest on wtedy odporny na pomyłki w słowie/literówki lub na słowa o podobnym znaczeniu (przy podobnej pisowni) - ponieważ będą miały one podobną wartość na wyjściu funkcji hashującej czyli będą tą samą cechą. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20139da166319b49eea5cc7e984fc08e",
     "grade": false,
     "grade_id": "cell-0d86672dbabbf54d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    " - W poprzednim zadaniu wczytałeś wynik grupowania Browna do pamięci. Wytrenuj klasyfikator na reprezentacji ,,Bag-of-clusters'' tj. w kolumnach zamiast słów/n-gramów będziesz miał grupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:13:08.990056Z",
     "start_time": "2020-03-22T18:12:39.433071Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b13c0457af5dab17e12780eafb1c5ac4",
     "grade": true,
     "grade_id": "cell-55264f6fe514d007",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5545371219065078, f1: 0.4799110180034512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# YOUR CODE HERE\n",
    "# brown_df[\"cluster\"].value_counts()\n",
    "# brown_df[brown_df[\"cluster\"] == 10010]\n",
    "\n",
    "word_to_cluster = {row['word']: row['cluster'] for _, row in brown_df.iterrows()}\n",
    "def transform_tokens_to_clusters(tokens_dataset, vectorizer, training=True):\n",
    "    clusters = []\n",
    "    for tokens in tokens_dataset:\n",
    "        clustered_tweet = []\n",
    "        for token in tokens:\n",
    "            try: \n",
    "                clustered_tweet.append(str(word_to_cluster[token]))\n",
    "            except KeyError:\n",
    "                pass\n",
    "        clusters.append(\" \".join(clustered_tweet))\n",
    "    return vectorizer.fit_transform(clusters) if training else vectorizer.transform(clusters)\n",
    "\n",
    "\n",
    "def fit_and_evaluate_model_boc(tokens_train, y_train, tokens_test, y_test):    \n",
    "    vectorizer = CountVectorizer(preprocessor=None, lowercase=False)\n",
    "    X_train = transform_tokens_to_clusters(tokens_train, vectorizer, True)\n",
    "    X_test = transform_tokens_to_clusters(tokens_test, vectorizer, False)\n",
    "\n",
    "    clf = SVC(kernel=\"linear\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_predict = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_predict)\n",
    "    f1 = f1_score(y_test, y_predict, average=\"macro\")\n",
    "    return clf, acc, f1\n",
    "\n",
    "clf, acc, f1 = fit_and_evaluate_model_boc(tokens_train, y_train, tokens_test, y_test)\n",
    "print(f\"Acc: {acc}, f1: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e47a053ebc12ac2fd97d9c11187da9b",
     "grade": false,
     "grade_id": "cell-493071698fc0205e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Podsumuj eksperymenty: poznałeś dwie możliwości ograniczenia liczby cech - zastąpienie słów ich grupami i haszowanie cech. Jakie są wady i zalety obydwu podejść?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b80ace505afba9b12fd5d3896a9046ef",
     "grade": true,
     "grade_id": "cell-4508400659f7243e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>Clustering</th>\n",
    "    <th>Feature Hasher</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Zalety</td>\n",
    "    <td>Można ustalić w pewien sposób jak dane słowa będą clustrowane - mamy w pewnym sensie wpływ na te clustry.<br><br>Złożoność obliczeniowa samego przyporządkowania słowo &gt; cluster jest niska.<br><br>Na poziomie jednego clustra słowa mogą mieć podobny sens lub podobną funkcję gramatyczną. <br><br></td>\n",
    "    <td>Niewrażliwość na literówki przy odpowiedniej ilości feature'ów.<br><br>Nie trzeba używać dodatkowego słownika który przyporządkuje słowo do feature'a, czyli nie ma potrzeby tworzenia takowego na jakimś korpusie, dzięki czemu brak problemu ze słowami spoza korpusu<br><br>Złożoność obliczeniowa jest niska.<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Wady</td>\n",
    "    <td>Uzyskanie grup może być czasochłonne. <br><br>Wrażliwy na literówki oraz problem ze słowami spoza korpusu. <br><br></td>\n",
    "    <td>Cechy nie są interpretowalne w podobny sensie jak grupy.<br><br>Wrażliwy na literówki oraz problem ze słowami spoza korpusu. <br><br></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
